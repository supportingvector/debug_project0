{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1448\n",
      "1168\n",
      "774\n",
      "785\n",
      "1313\n"
     ]
    }
   ],
   "source": [
    "from social_utils import SocialDataLoader\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import rnn_cell\n",
    "from grid import getSequenceGridMask\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "batch_size=50\n",
    "seq_length=5\n",
    "maxNumPeds=40\n",
    "datasets=[0, 1, 2, 3, 4]\n",
    "grid_size = 8\n",
    "neighborhood_size=32\n",
    "num_epochs=1\n",
    "data_loader = SocialDataLoader()\n",
    "x,y,d=data_loader.next_batch()\n",
    "sess= tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SocialModel():\n",
    "\n",
    "    def __init__(self, infer=False):\n",
    "        '''\n",
    "        args \n",
    "        '''\n",
    "        # If sampling new trajectories, then infer mode\n",
    "        if infer:\n",
    "            # Sample one position at a time\n",
    "            batch_size = 1\n",
    "            aseq_length = 1\n",
    "        # Store the arguments\n",
    "        self.infer = infer\n",
    "        # Store rnn size and grid_size\n",
    "        self.rnn_size = 128\n",
    "        self.grid_size = 8\n",
    "        # Maximum number of peds\n",
    "        self.maxNumPeds =30\n",
    "        self.seq_length=5\n",
    "        self.maxNumPeds=40\n",
    "        self.embedding_size=64\n",
    "        self.output_size = 5\n",
    "        self.learning_rate=0.0001\n",
    "        \n",
    "        '''\n",
    "        model\n",
    "        '''\n",
    "        with tf.name_scope(\"LSTM_cell\"):\n",
    "        #with tf.name_scope(\"LSTM_cell\",reuse=True):\n",
    "            cell = rnn_cell.BasicLSTMCell(self.rnn_size, state_is_tuple=False)\n",
    "        self.input_data = tf.placeholder(tf.float32, \n",
    "                                         [self.seq_length, self.maxNumPeds, 3], name=\"input_data\")\n",
    "        #self.input_data维度为(seq_length,maxNumPeds，3)\n",
    "        \n",
    "        self.target_data = tf.placeholder(tf.float32, \n",
    "                                          [self.seq_length, self.maxNumPeds, 3], name=\"target_data\")\n",
    "        #self.target_data维度为(seq_length,maxNumPeds，3)\n",
    "        \n",
    "        # Grid data would be a binary matrix which encodes whether a pedestrian is present in\n",
    "        # a grid cell of other pedestrian\n",
    "        self.grid_data = tf.placeholder(tf.float32,\n",
    "                                        [self.seq_length, self.maxNumPeds,\n",
    "                                         self.maxNumPeds, self.grid_size*self.grid_size], name=\"grid_data\")\n",
    "        self.lr = tf.Variable(self.learning_rate, trainable=False, name=\"learning_rate\")\n",
    "        \n",
    "        \n",
    "        # Define LSTM states for each pedestrian\n",
    "        # maxNumPeds每一帧最大行人数目\n",
    "        with tf.variable_scope(\"LSTM_states\"):\n",
    "        #with tf.variable_scope(\"LSTM_states\",reuse=True):\n",
    "            self.LSTM_states = tf.zeros([self.maxNumPeds, cell.state_size], name=\"LSTM_states\")\n",
    "            self.initial_states = tf.split(axis=0,\n",
    "                                           num_or_size_splits=self.maxNumPeds, value=self.LSTM_states)\n",
    "            #将LSTM_state变成一个list，有MaxNumPeds个元素，每个为256维（一个lstm有128*2个维度hidden units）\n",
    "        \n",
    "        # Define hidden output states for each pedestrian\n",
    "        with tf.variable_scope(\"Hidden_states\"):\n",
    "        #with tf.variable_scope(\"Hidden_states\",reuse=True):\n",
    "            # self.output_states = tf.zeros([args.maxNumPeds, cell.output_size], name=\"hidden_states\")\n",
    "            self.output_states = tf.split(axis=0, num_or_size_splits=self.maxNumPeds, value=tf.zeros([self.maxNumPeds, cell.output_size]))\n",
    "            #将LSTM_state变成一个list，有MaxNumPeds个元素，每个为output_size维度）\n",
    "    \n",
    "    \n",
    "        # List of tensors each of shape args.maxNumPedsx3 corresponding to each frame in the sequence\n",
    "        with tf.name_scope(\"frame_data_tensors\"):\n",
    "        #with tf.name_scope(\"frame_data_tensors\",reuse=True):\n",
    "            # frame_data = tf.split(0, args.seq_length, self.input_data, name=\"frame_data\")\n",
    "            frame_data = [tf.squeeze(input_, [0]) \n",
    "                          for input_ in tf.split(axis=0, num_or_size_splits=self.seq_length, value=self.input_data)]\n",
    "            #组成一个list，list包含seq_length个元素，每个元素shape为（maxNumPeds，3）\n",
    "       \n",
    "    \n",
    "        with tf.name_scope(\"frame_target_data_tensors\"):\n",
    "        #with tf.name_scope(\"frame_target_data_tensors\",reuse=True):\n",
    "            # frame_target_data = tf.split(0, args.seq_length, self.target_data, name=\"frame_target_data\")\n",
    "            self.frame_target_data = [tf.squeeze(target_, [0]) \n",
    "                                      for target_ in tf.split(axis=0, num_or_size_splits=self.seq_length, value=self.target_data)]\n",
    "            #组成一个list，list包含seq_length个元素，每个元素shape为（maxNumPeds，3）            \n",
    "            \n",
    "          \n",
    "        with tf.name_scope(\"grid_frame_data_tensors\"):\n",
    "        #with tf.name_scope(\"grid_frame_data_tensors\",reuse=True):\n",
    "            # This would contain a list of tensors each of shape MNP x MNP x (GS**2) encoding the mask\n",
    "            # grid_frame_data = tf.split(0, args.seq_length, self.grid_data, name=\"grid_frame_data\")\n",
    "            grid_frame_data = [tf.squeeze(input_, [0]) for input_ in tf.split(axis=0, num_or_size_splits=self.seq_length, value=self.grid_data)]    \n",
    "            #组成一个list，list包含seq_length个元素，每个元素shape为（self.maxNumPeds, self.maxNumPeds, self.grid_size*self.grid_size）\n",
    "  \n",
    "\n",
    "        # Cost的一些参数\n",
    "        with tf.name_scope(\"Cost_related_stuff\"):\n",
    "        #with tf.name_scope(\"Cost_related_stuff\",reuse=True):\n",
    "            self.cost = tf.constant(0.0, name=\"cost\")\n",
    "            self.counter = tf.constant(0.0, name=\"counter\")\n",
    "            self.increment = tf.constant(1.0, name=\"increment\")\n",
    "            \n",
    "            \n",
    "        # Containers to store output distribution parameters\n",
    "        with tf.name_scope(\"Distribution_parameters_stuff\"):\n",
    "            # self.initial_output = tf.zeros([args.maxNumPeds, self.output_size], name=\"distribution_parameters\")\n",
    "            self.initial_output = tf.split(axis=0, num_or_size_splits=self.maxNumPeds, value=tf.zeros([self.maxNumPeds, self.output_size]))            \n",
    "            #组成一个list，list包含seq_length个元素，每个元素shape为（self.output_size）\n",
    "        for seq, frame in enumerate(frame_data):\n",
    "            print(\"Frame number\", seq)\n",
    "            current_frame_data = frame  \n",
    "            # MNP x 3 tensor\n",
    "            current_grid_frame_data = grid_frame_data[seq] \n",
    "            # MNP x MNP x (GS**2) tensor\n",
    "            social_tensor = tf.zeros([\n",
    "                    self.maxNumPeds, self.grid_size*self.grid_size*self.rnn_size])\n",
    "            for ped in range(self.maxNumPeds):\n",
    "                print(\"Pedestrian Number\", ped)\n",
    "                pedID = current_frame_data[ped, 0]\n",
    "                with tf.name_scope(\"extract_input_ped\"):\n",
    "                    self.spatial_input = tf.slice(current_frame_data, [ped, 1], [1, 2])\n",
    "                    # Tensor of shape (1,2)\n",
    "                    # Extract x and y positions of the current ped\n",
    "                    self.tensor_input = tf.slice(social_tensor, \n",
    "                                                 [ped, 0],[1, self.grid_size*self.grid_size*self.rnn_size])\n",
    "                    # current ped对应的social\n",
    "                with tf.name_scope(\"embeddings_operations\"):\n",
    "                    embedded_spatial_input = tf.nn.relu(\n",
    "                        tf.nn.xw_plus_b(self.spatial_input, self.embedding_w, self.embedding_b))\n",
    "                    embedded_tensor_input = tf.nn.relu(\n",
    "                        tf.nn.xw_plus_b(self.tensor_input, self.embedding_t_w, self.embedding_t_b))\n",
    "\"\"\"\n",
    "Embedding\n",
    "\"\"\"\n",
    "        \n",
    "    def define_embedding_and_output_layers(self, args):\n",
    "        # Define variables for the spatial coordinates embedding layer\n",
    "        with tf.variable_scope(\"coordinate_embedding\"):\n",
    "            self.embedding_w = tf.get_variable(\"embedding_w\", [2, args.embedding_size], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "            self.embedding_b = tf.get_variable(\"embedding_b\", [args.embedding_size], initializer=tf.constant_initializer(0.01))\n",
    "\n",
    "        # Define variables for the social tensor embedding layer\n",
    "        with tf.variable_scope(\"tensor_embedding\"):\n",
    "            self.embedding_t_w = tf.get_variable(\"embedding_t_w\", [args.grid_size*args.grid_size*args.rnn_size, args.embedding_size], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "            self.embedding_t_b = tf.get_variable(\"embedding_t_b\", [args.embedding_size], initializer=tf.constant_initializer(0.01))\n",
    "\n",
    "        # Define variables for the output linear layer\n",
    "        with tf.variable_scope(\"output_layer\"):\n",
    "            self.output_w = tf.get_variable(\"output_w\", [args.rnn_size, self.output_size], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "            self.output_b = tf.get_variable(\"output_b\", [self.output_size], initializer=tf.constant_initializer(0.01))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??tf.slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1448\n",
      "1168\n",
      "774\n",
      "785\n",
      "1313\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002690CAEB9B0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator.USER01703281353\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "datasets = range(4)\n",
    "data_loader = SocialDataLoader()\n",
    "model = SocialModel()\n",
    "    # Initialize all variables in the graph\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for e in range(num_epochs):\n",
    "    data_loader.reset_batch_pointer()\n",
    "    for b in range(data_loader.num_batches):\n",
    "        start = time.time()\n",
    "        x, y, d = data_loader.next_batch()\n",
    "        #模型输入为【batch_size,seq_length,maxNumPeds,3】\n",
    "        loss_batch = 0\n",
    "        for batch in range(data_loader.batch_size):\n",
    "            x_batch, y_batch, d_batch = x[batch], y[batch], d[batch]\n",
    "            #x_batch..变成了【seq_length,maxNumPeds,3】\n",
    "            if d_batch == 0 and datasets[0] == 0:\n",
    "                dataset_data = [640, 480]\n",
    "            else:\n",
    "                dataset_data = [720, 576]\n",
    "            grid_batch = getSequenceGridMask(x_batch, dataset_data,neighborhood_size, grid_size)\n",
    "            feed = {model.input_data: x_batch, model.target_data: y_batch, model.grid_data: grid_batch}\n",
    "            LSTM_state,input_data= sess.run([model.LSTM_states,model.input_data], feed)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 40, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(initial_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??pd.read_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
